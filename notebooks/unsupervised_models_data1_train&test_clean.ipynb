{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85d24ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# be careful with that:\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, confusion_matrix, recall_score, pairwise_distances_argmin_min\n",
    "from sklearn.metrics import precision_score, f1_score\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f38399",
   "metadata": {},
   "source": [
    "# Training and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1a29a",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58f5d8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb components:  200\n",
      "Data directory:  ../datasets/train/data_heatmap_train.csv\n"
     ]
    }
   ],
   "source": [
    "# read the training data of data I from datasets folder\n",
    "!python3 pca_pipeline_combine_gridid.py 200 '../datasets/train/data_heatmap_train.csv'\n",
    "\n",
    "pca_df = pd.read_csv('temp/pca_df.csv')\n",
    "pca_df = pca_df.iloc[:,1:]\n",
    "pca_df_inp = pca_df.iloc[:,:-2]\n",
    "y_train = pca_df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed819f2",
   "metadata": {},
   "source": [
    "## One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96f4f2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for 2 PCA dimensions:\n",
      "  [[609 484]\n",
      " [  0 119]]\n",
      "Accuracy for 2 PCA dimensions:  0.60\n",
      "Recall for 2 PCA dimensions:  1.00\n",
      "Precision for 2 PCA dimensions:  0.20\n",
      "F1 for 2 PCA dimensions:  0.52\n",
      "---------\n",
      "Confusion matrix for 14 PCA dimensions:\n",
      "  [[614 479]\n",
      " [  0 119]]\n",
      "Accuracy for 14 PCA dimensions:  0.60\n",
      "Recall for 14 PCA dimensions:  1.00\n",
      "Precision for 14 PCA dimensions:  0.20\n",
      "F1 for 14 PCA dimensions:  0.53\n",
      "---------\n",
      "Confusion matrix for 39 PCA dimensions:\n",
      "  [[617 476]\n",
      " [  0 119]]\n",
      "Accuracy for 39 PCA dimensions:  0.61\n",
      "Recall for 39 PCA dimensions:  1.00\n",
      "Precision for 39 PCA dimensions:  0.20\n",
      "F1 for 39 PCA dimensions:  0.53\n",
      "---------\n",
      "Confusion matrix for 51 PCA dimensions:\n",
      "  [[618 475]\n",
      " [  0 119]]\n",
      "Accuracy for 51 PCA dimensions:  0.61\n",
      "Recall for 51 PCA dimensions:  1.00\n",
      "Precision for 51 PCA dimensions:  0.20\n",
      "F1 for 51 PCA dimensions:  0.53\n",
      "---------\n",
      "Confusion matrix for 153 PCA dimensions:\n",
      "  [[700 393]\n",
      " [ 26  93]]\n",
      "Accuracy for 153 PCA dimensions:  0.65\n",
      "Recall for 153 PCA dimensions:  0.78\n",
      "Precision for 153 PCA dimensions:  0.19\n",
      "F1 for 153 PCA dimensions:  0.54\n",
      "---------\n",
      "Confusion matrix for 154 PCA dimensions:\n",
      "  [[706 387]\n",
      " [ 25  94]]\n",
      "Accuracy for 154 PCA dimensions:  0.66\n",
      "Recall for 154 PCA dimensions:  0.79\n",
      "Precision for 154 PCA dimensions:  0.20\n",
      "F1 for 154 PCA dimensions:  0.54\n",
      "---------\n",
      "Confusion matrix for 158 PCA dimensions:\n",
      "  [[715 378]\n",
      " [ 26  93]]\n",
      "Accuracy for 158 PCA dimensions:  0.67\n",
      "Recall for 158 PCA dimensions:  0.78\n",
      "Precision for 158 PCA dimensions:  0.20\n",
      "F1 for 158 PCA dimensions:  0.55\n",
      "---------\n",
      "Confusion matrix for 159 PCA dimensions:\n",
      "  [[724 369]\n",
      " [ 28  91]]\n",
      "Accuracy for 159 PCA dimensions:  0.67\n",
      "Recall for 159 PCA dimensions:  0.76\n",
      "Precision for 159 PCA dimensions:  0.20\n",
      "F1 for 159 PCA dimensions:  0.55\n",
      "---------\n",
      "Confusion matrix for 171 PCA dimensions:\n",
      "  [[832 261]\n",
      " [ 54  65]]\n",
      "Accuracy for 171 PCA dimensions:  0.74\n",
      "Recall for 171 PCA dimensions:  0.55\n",
      "Precision for 171 PCA dimensions:  0.20\n",
      "F1 for 171 PCA dimensions:  0.57\n",
      "---------\n",
      "Confusion matrix for 172 PCA dimensions:\n",
      "  [[849 244]\n",
      " [ 43  76]]\n",
      "Accuracy for 172 PCA dimensions:  0.76\n",
      "Recall for 172 PCA dimensions:  0.64\n",
      "Precision for 172 PCA dimensions:  0.24\n",
      "F1 for 172 PCA dimensions:  0.60\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "pca_df_inp = pca_df.iloc[:,:-2]\n",
    "best_acc = -float('inf')\n",
    "best_dim = -1\n",
    "best_recall = -1\n",
    "best_prec = -1\n",
    "best_f1 = -1\n",
    "\n",
    "# try different values of PCA dimension\n",
    "for pca_dim in np.linspace(2,200,198).astype(int):\n",
    "    X = pca_df_inp.iloc[:,:pca_dim]\n",
    "    \n",
    "    oneclass = OneClassSVM(gamma = 'auto').fit(X)\n",
    "    oneclass_labels = oneclass.predict(X)\n",
    "    \n",
    "    oneclass_labels = np.where(oneclass_labels == 1, 0,1)\n",
    "    \n",
    "    conf_mat   = confusion_matrix(y_train,oneclass_labels)\n",
    "    acc        = accuracy_score(y_train,oneclass_labels)\n",
    "    recall     = recall_score(y_train,oneclass_labels)\n",
    "    prec       = precision_score(y_train,oneclass_labels)\n",
    "    f1         = f1_score(y_train,oneclass_labels,average='macro')\n",
    "    \n",
    "    # store the current best macro f1 and other corresponding metrics\n",
    "    if f1 > best_f1:\n",
    "        best_acc = acc\n",
    "        best_dim = pca_dim\n",
    "        best_recall  = recall\n",
    "        best_prec = prec\n",
    "        best_f1 = f1\n",
    "        \n",
    "        best_oneclass_labels = oneclass_labels\n",
    "        \n",
    "        print(f'Confusion matrix for {pca_dim} PCA dimensions:\\n', \n",
    "              f' {conf_mat}')\n",
    "        print(f'Accuracy for {pca_dim} PCA dimensions:', \n",
    "              f' {acc:.2f}')\n",
    "        print(f'Recall for {pca_dim} PCA dimensions:', \n",
    "              f' {recall:.2f}')\n",
    "        print(f'Precision for {pca_dim} PCA dimensions:', \n",
    "              f' {prec:.2f}')\n",
    "        print(f'F1 for {pca_dim} PCA dimensions:', \n",
    "              f' {f1:.2f}')\n",
    "        print(f'---------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892686ea",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dc41a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for 2 PCA dimensions, 90 threshold and 1-NN:\n",
      "  [[1093    0]\n",
      " [ 119    0]]\n",
      "Accuracy for 2 PCA dimensions, 90 threshold and 1-NN:  0.90\n",
      "F1 for 2 PCA dimensions, 90 threshold and 1-NN:  0.47\n",
      "---------\n",
      "Confusion matrix for 2 PCA dimensions, 90 threshold and 2-NN:\n",
      "  [[1042   51]\n",
      " [  48   71]]\n",
      "Accuracy for 2 PCA dimensions, 90 threshold and 2-NN:  0.92\n",
      "F1 for 2 PCA dimensions, 90 threshold and 2-NN:  0.77\n",
      "---------\n",
      "Confusion matrix for 2 PCA dimensions, 90 threshold and 5-NN:\n",
      "  [[1043   50]\n",
      " [  47   72]]\n",
      "Accuracy for 2 PCA dimensions, 90 threshold and 5-NN:  0.92\n",
      "F1 for 2 PCA dimensions, 90 threshold and 5-NN:  0.78\n",
      "---------\n",
      "Confusion matrix for 2 PCA dimensions, 90 threshold and 10-NN:\n",
      "  [[1049   44]\n",
      " [  41   78]]\n",
      "Accuracy for 2 PCA dimensions, 90 threshold and 10-NN:  0.93\n",
      "F1 for 2 PCA dimensions, 90 threshold and 10-NN:  0.80\n",
      "---------\n",
      "Confusion matrix for 4 PCA dimensions, 90 threshold and 2-NN:\n",
      "  [[1053   40]\n",
      " [  37   82]]\n",
      "Accuracy for 4 PCA dimensions, 90 threshold and 2-NN:  0.94\n",
      "F1 for 4 PCA dimensions, 90 threshold and 2-NN:  0.82\n",
      "---------\n",
      "Confusion matrix for 4 PCA dimensions, 90 threshold and 5-NN:\n",
      "  [[1063   30]\n",
      " [  27   92]]\n",
      "Accuracy for 4 PCA dimensions, 90 threshold and 5-NN:  0.95\n",
      "F1 for 4 PCA dimensions, 90 threshold and 5-NN:  0.87\n",
      "---------\n",
      "Confusion matrix for 4 PCA dimensions, 90 threshold and 10-NN:\n",
      "  [[1067   26]\n",
      " [  23   96]]\n",
      "Accuracy for 4 PCA dimensions, 90 threshold and 10-NN:  0.96\n",
      "F1 for 4 PCA dimensions, 90 threshold and 10-NN:  0.89\n",
      "---------\n",
      "Confusion matrix for 6 PCA dimensions, 90 threshold and 5-NN:\n",
      "  [[1068   25]\n",
      " [  22   97]]\n",
      "Accuracy for 6 PCA dimensions, 90 threshold and 5-NN:  0.96\n",
      "F1 for 6 PCA dimensions, 90 threshold and 5-NN:  0.89\n",
      "---------\n",
      "Confusion matrix for 6 PCA dimensions, 90 threshold and 10-NN:\n",
      "  [[1072   21]\n",
      " [  18  101]]\n",
      "Accuracy for 6 PCA dimensions, 90 threshold and 10-NN:  0.97\n",
      "F1 for 6 PCA dimensions, 90 threshold and 10-NN:  0.91\n",
      "---------\n",
      "Confusion matrix for 8 PCA dimensions, 90 threshold and 10-NN:\n",
      "  [[1074   19]\n",
      " [  16  103]]\n",
      "Accuracy for 8 PCA dimensions, 90 threshold and 10-NN:  0.97\n",
      "F1 for 8 PCA dimensions, 90 threshold and 10-NN:  0.92\n",
      "---------\n",
      "Confusion matrix for 10 PCA dimensions, 90 threshold and 10-NN:\n",
      "  [[1075   18]\n",
      " [  15  104]]\n",
      "Accuracy for 10 PCA dimensions, 90 threshold and 10-NN:  0.97\n",
      "F1 for 10 PCA dimensions, 90 threshold and 10-NN:  0.92\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "pca_df_inp = pca_df.iloc[:,:-2]\n",
    "kchoices = [1,2,5,10]\n",
    "thres    = [90, 95, 99]\n",
    "best_acc = -float('inf')\n",
    "best_dim = -1\n",
    "best_f1 = -float('inf')\n",
    "\n",
    "# try different values of k, threshold and PCA dimension \n",
    "for pca_dim in np.linspace(2,200,100).astype(int):\n",
    "    for ks in kchoices:\n",
    "        for an_thres in thres:\n",
    "            X   = pca_df_inp.iloc[:,:pca_dim]\n",
    "            knn = NearestNeighbors(n_neighbors = ks, \n",
    "                                   algorithm = 'auto', \n",
    "                                   metric = 'euclidean')\n",
    "\n",
    "            knn_fit = knn.fit(X)\n",
    "            distances, indices = knn.kneighbors(X)\n",
    "            anomaly_scores = distances.mean(axis=1)\n",
    "\n",
    "            threshold  = np.percentile(anomaly_scores, an_thres)\n",
    "            knn_labels = anomaly_scores > threshold\n",
    "\n",
    "            conf_mat = confusion_matrix(y_train,knn_labels)\n",
    "            acc        = accuracy_score(y_train,knn_labels)\n",
    "            f1         = f1_score(y_train,knn_labels,average='macro')\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_knn_labels = knn_labels\n",
    "                best_acc = acc\n",
    "                best_dim = pca_dim\n",
    "                best_f1 = f1\n",
    "\n",
    "                print(f'Confusion matrix for {pca_dim} PCA dimensions, {an_thres} threshold and {ks}-NN:\\n', \n",
    "                      f' {conf_mat}')\n",
    "                print(f'Accuracy for {pca_dim} PCA dimensions, {an_thres} threshold and {ks}-NN:', \n",
    "                      f' {acc:.2f}')\n",
    "                print(f'F1 for {pca_dim} PCA dimensions, {an_thres} threshold and {ks}-NN:', \n",
    "                      f' {f1:.2f}')\n",
    "                print(f'---------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bb8f29",
   "metadata": {},
   "source": [
    "## Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee7f1465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best confusion matrix: \n",
      "[[1090    3]\n",
      " [  61   58]]\n",
      "Best PCA dimension: 2\n",
      "Best K: 2\n",
      "Best accuracy: 0.95\n",
      "Best precision: 0.95\n",
      "Best recall: 0.49\n",
      "Best f1-score: 0.81\n"
     ]
    }
   ],
   "source": [
    "# distance from centroid approach\n",
    "kchoices = [2,3,4,5,6]\n",
    "best_f1 = -1\n",
    "\n",
    "# try different values of k and PCA dimension \n",
    "for k in kchoices:\n",
    "    for pca_dim in np.linspace(2,200,50).astype(int):\n",
    "        X = pca_df_inp.iloc[:,list(range(pca_dim)) + [-1]]\n",
    "        # one_hot = pd.get_dummies(X['grid_id'], prefix='grid')\n",
    "        # X = X.join(one_hot)\n",
    "\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42).fit(X)\n",
    "        centroids = kmeans.cluster_centers_\n",
    "        labels = kmeans.labels_\n",
    "\n",
    "        # Calculate the distance from each point to its cluster centroid\n",
    "        closest, distances = pairwise_distances_argmin_min(X, centroids[labels])\n",
    "        # distances = euclidean_distances(data_normalized, centroids[labels])\n",
    "\n",
    "        # Choose a threshold for flagging an anomaly\n",
    "        threshold = np.percentile(distances, 95)\n",
    "\n",
    "        # Anything above the threshold is considered an anomaly\n",
    "        anomalies = pca_df_inp[distances > threshold]\n",
    "\n",
    "        kmeans_labels = (distances > threshold).astype(int)\n",
    "      \n",
    "        f1 = f1_score(y_train,kmeans_labels,average='macro')\n",
    "      \n",
    "        if f1 > best_f1:\n",
    "            best_acc = accuracy_score(y_train,kmeans_labels)\n",
    "            best_dim = pca_dim\n",
    "            best_k = k\n",
    "            best_recall  = recall_score(y_train,kmeans_labels)\n",
    "            best_prec = precision_score(y_train,kmeans_labels)\n",
    "            best_conf_mat = confusion_matrix(y_train,kmeans_labels)\n",
    "            best_f1 = f1\n",
    "\n",
    "print(f'Best confusion matrix: \\n{best_conf_mat}')\n",
    "print(f'Best PCA dimension: {best_dim}')\n",
    "print(f'Best K: {best_k}')\n",
    "print(f'Best accuracy: {best_acc:.2f}')\n",
    "print(f'Best precision: {best_prec:.2f}')\n",
    "print(f'Best recall: {best_recall:.2f}')\n",
    "print(f'Best f1-score: {best_f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145bd538",
   "metadata": {},
   "source": [
    "## DBScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1494d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for 2 PCA dimensions:\n",
      "  [[1093    0]\n",
      " [ 115    4]]\n",
      "Accuracy for 2 PCA dimensions:  0.91\n",
      "Recall for 2 PCA dimensions:  0.03\n",
      "Precision for 2 PCA dimensions:  1.00\n",
      "F1 for 2 PCA dimensions, 5 eps, and 2 min_samps :  0.51\n",
      "---------\n",
      "Confusion matrix for 2 PCA dimensions:\n",
      "  [[1093    0]\n",
      " [ 111    8]]\n",
      "Accuracy for 2 PCA dimensions:  0.91\n",
      "Recall for 2 PCA dimensions:  0.07\n",
      "Precision for 2 PCA dimensions:  1.00\n",
      "F1 for 2 PCA dimensions, 5 eps, and 3 min_samps :  0.54\n",
      "---------\n",
      "Confusion matrix for 2 PCA dimensions:\n",
      "  [[1093    0]\n",
      " [ 107   12]]\n",
      "Accuracy for 2 PCA dimensions:  0.91\n",
      "Recall for 2 PCA dimensions:  0.10\n",
      "Precision for 2 PCA dimensions:  1.00\n",
      "F1 for 2 PCA dimensions, 5 eps, and 5 min_samps :  0.57\n",
      "---------\n",
      "Confusion matrix for 2 PCA dimensions:\n",
      "  [[1093    0]\n",
      " [ 101   18]]\n",
      "Accuracy for 2 PCA dimensions:  0.92\n",
      "Recall for 2 PCA dimensions:  0.15\n",
      "Precision for 2 PCA dimensions:  1.00\n",
      "F1 for 2 PCA dimensions, 5 eps, and 10 min_samps :  0.61\n",
      "---------\n",
      "Confusion matrix for 4 PCA dimensions:\n",
      "  [[1092    1]\n",
      " [  93   26]]\n",
      "Accuracy for 4 PCA dimensions:  0.92\n",
      "Recall for 4 PCA dimensions:  0.22\n",
      "Precision for 4 PCA dimensions:  0.96\n",
      "F1 for 4 PCA dimensions, 5 eps, and 4 min_samps :  0.66\n",
      "---------\n",
      "Confusion matrix for 4 PCA dimensions:\n",
      "  [[1092    1]\n",
      " [  89   30]]\n",
      "Accuracy for 4 PCA dimensions:  0.93\n",
      "Recall for 4 PCA dimensions:  0.25\n",
      "Precision for 4 PCA dimensions:  0.97\n",
      "F1 for 4 PCA dimensions, 5 eps, and 5 min_samps :  0.68\n",
      "---------\n",
      "Confusion matrix for 4 PCA dimensions:\n",
      "  [[1090    3]\n",
      " [  83   36]]\n",
      "Accuracy for 4 PCA dimensions:  0.93\n",
      "Recall for 4 PCA dimensions:  0.30\n",
      "Precision for 4 PCA dimensions:  0.92\n",
      "F1 for 4 PCA dimensions, 5 eps, and 10 min_samps :  0.71\n",
      "---------\n",
      "Confusion matrix for 6 PCA dimensions:\n",
      "  [[1089    4]\n",
      " [  81   38]]\n",
      "Accuracy for 6 PCA dimensions:  0.93\n",
      "Recall for 6 PCA dimensions:  0.32\n",
      "Precision for 6 PCA dimensions:  0.90\n",
      "F1 for 6 PCA dimensions, 5 eps, and 2 min_samps :  0.72\n",
      "---------\n",
      "Confusion matrix for 6 PCA dimensions:\n",
      "  [[1087    6]\n",
      " [  73   46]]\n",
      "Accuracy for 6 PCA dimensions:  0.93\n",
      "Recall for 6 PCA dimensions:  0.39\n",
      "Precision for 6 PCA dimensions:  0.88\n",
      "F1 for 6 PCA dimensions, 5 eps, and 3 min_samps :  0.75\n",
      "---------\n",
      "Confusion matrix for 6 PCA dimensions:\n",
      "  [[1087    6]\n",
      " [  69   50]]\n",
      "Accuracy for 6 PCA dimensions:  0.94\n",
      "Recall for 6 PCA dimensions:  0.42\n",
      "Precision for 6 PCA dimensions:  0.89\n",
      "F1 for 6 PCA dimensions, 5 eps, and 4 min_samps :  0.77\n",
      "---------\n",
      "Confusion matrix for 6 PCA dimensions:\n",
      "  [[1087    6]\n",
      " [  59   60]]\n",
      "Accuracy for 6 PCA dimensions:  0.95\n",
      "Recall for 6 PCA dimensions:  0.50\n",
      "Precision for 6 PCA dimensions:  0.91\n",
      "F1 for 6 PCA dimensions, 5 eps, and 5 min_samps :  0.81\n",
      "---------\n",
      "Confusion matrix for 6 PCA dimensions:\n",
      "  [[1083   10]\n",
      " [  19  100]]\n",
      "Accuracy for 6 PCA dimensions:  0.98\n",
      "Recall for 6 PCA dimensions:  0.84\n",
      "Precision for 6 PCA dimensions:  0.91\n",
      "F1 for 6 PCA dimensions, 5 eps, and 10 min_samps :  0.93\n",
      "---------\n",
      "Confusion matrix for 8 PCA dimensions:\n",
      "  [[1070   23]\n",
      " [   1  118]]\n",
      "Accuracy for 8 PCA dimensions:  0.98\n",
      "Recall for 8 PCA dimensions:  0.99\n",
      "Precision for 8 PCA dimensions:  0.84\n",
      "F1 for 8 PCA dimensions, 5 eps, and 10 min_samps :  0.95\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "pca_df_inp = pca_df.iloc[:,:-2]\n",
    "epsilons = [5,10,20,30,40,50,60,70,80,90,100]\n",
    "min_samps = [2,3,4,5,10]\n",
    "\n",
    "best_acc = -float('inf')\n",
    "best_dim = -1\n",
    "best_recall = -1\n",
    "best_prec = -1\n",
    "best_f1 = -1\n",
    "\n",
    "# try different values of epsilon, minimum samples and PCA dimension \n",
    "for pca_dim in np.linspace(2,200,100).astype(int):\n",
    "    for eps in epsilons:\n",
    "        for ms in min_samps:\n",
    "\n",
    "            X   = pca_df_inp.iloc[:,:pca_dim]\n",
    "\n",
    "            dbscan = DBSCAN(eps = eps, min_samples = ms)\n",
    "            dbscan_labels = dbscan.fit_predict(X)\n",
    "            dbscan_labels = np.where(dbscan_labels>=0, 0, 1)\n",
    "\n",
    "            conf_mat   = confusion_matrix(y_train,dbscan_labels)\n",
    "            acc        = accuracy_score(y_train,dbscan_labels)\n",
    "            recall     = recall_score(y_train,dbscan_labels)\n",
    "            prec       = precision_score(y_train,dbscan_labels)\n",
    "            f1         = f1_score(y_train,dbscan_labels,average='macro')\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_acc = acc\n",
    "                best_dim = pca_dim\n",
    "                best_recall  = recall\n",
    "                best_prec = prec\n",
    "                best_dbscan_labels = dbscan_labels\n",
    "                best_f1 = f1\n",
    "\n",
    "                print(f'Confusion matrix for {pca_dim} PCA dimensions:\\n', \n",
    "                      f' {conf_mat}')\n",
    "                print(f'Accuracy for {pca_dim} PCA dimensions:', \n",
    "                      f' {acc:.2f}')\n",
    "                print(f'Recall for {pca_dim} PCA dimensions:', \n",
    "                      f' {recall:.2f}')\n",
    "                print(f'Precision for {pca_dim} PCA dimensions:', \n",
    "                      f' {prec:.2f}')\n",
    "                print(f'F1 for {pca_dim} PCA dimensions, {eps} eps, and {ms} min_samps :', \n",
    "                      f' {f1:.2f}')\n",
    "                print(f'---------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e333fe95",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "510f1767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for 2 PCA dimensions:\n",
      "  [[832 261]\n",
      " [ 67  52]]\n",
      "Accuracy for 2 PCA dimensions:  0.73\n",
      "Recall for 2 PCA dimensions:  0.44\n",
      "Precision for 2 PCA dimensions:  0.17\n",
      "F1 for 2 PCA dimensions, 5 n_estimator  0.54\n",
      "---------\n",
      "Confusion matrix for 2 PCA dimensions:\n",
      "  [[910 183]\n",
      " [ 74  45]]\n",
      "Accuracy for 2 PCA dimensions:  0.79\n",
      "Recall for 2 PCA dimensions:  0.38\n",
      "Precision for 2 PCA dimensions:  0.20\n",
      "F1 for 2 PCA dimensions, 10 n_estimator  0.57\n",
      "---------\n",
      "Confusion matrix for 2 PCA dimensions:\n",
      "  [[977 116]\n",
      " [  0 119]]\n",
      "Accuracy for 2 PCA dimensions:  0.90\n",
      "Recall for 2 PCA dimensions:  1.00\n",
      "Precision for 2 PCA dimensions:  0.51\n",
      "F1 for 2 PCA dimensions, 50 n_estimator  0.81\n",
      "---------\n",
      "Confusion matrix for 2 PCA dimensions:\n",
      "  [[980 113]\n",
      " [  0 119]]\n",
      "Accuracy for 2 PCA dimensions:  0.91\n",
      "Recall for 2 PCA dimensions:  1.00\n",
      "Precision for 2 PCA dimensions:  0.51\n",
      "F1 for 2 PCA dimensions, 100 n_estimator  0.81\n",
      "---------\n",
      "Confusion matrix for 4 PCA dimensions:\n",
      "  [[1075   18]\n",
      " [  48   71]]\n",
      "Accuracy for 4 PCA dimensions:  0.95\n",
      "Recall for 4 PCA dimensions:  0.60\n",
      "Precision for 4 PCA dimensions:  0.80\n",
      "F1 for 4 PCA dimensions, 10 n_estimator  0.83\n",
      "---------\n",
      "Confusion matrix for 4 PCA dimensions:\n",
      "  [[1074   19]\n",
      " [  29   90]]\n",
      "Accuracy for 4 PCA dimensions:  0.96\n",
      "Recall for 4 PCA dimensions:  0.76\n",
      "Precision for 4 PCA dimensions:  0.83\n",
      "F1 for 4 PCA dimensions, 50 n_estimator  0.88\n",
      "---------\n",
      "Confusion matrix for 4 PCA dimensions:\n",
      "  [[1077   16]\n",
      " [  25   94]]\n",
      "Accuracy for 4 PCA dimensions:  0.97\n",
      "Recall for 4 PCA dimensions:  0.79\n",
      "Precision for 4 PCA dimensions:  0.85\n",
      "F1 for 4 PCA dimensions, 100 n_estimator  0.90\n",
      "---------\n",
      "Confusion matrix for 8 PCA dimensions:\n",
      "  [[1085    8]\n",
      " [  30   89]]\n",
      "Accuracy for 8 PCA dimensions:  0.97\n",
      "Recall for 8 PCA dimensions:  0.75\n",
      "Precision for 8 PCA dimensions:  0.92\n",
      "F1 for 8 PCA dimensions, 50 n_estimator  0.90\n",
      "---------\n",
      "Confusion matrix for 8 PCA dimensions:\n",
      "  [[1083   10]\n",
      " [  27   92]]\n",
      "Accuracy for 8 PCA dimensions:  0.97\n",
      "Recall for 8 PCA dimensions:  0.77\n",
      "Precision for 8 PCA dimensions:  0.90\n",
      "F1 for 8 PCA dimensions, 100 n_estimator  0.91\n",
      "---------\n",
      "Confusion matrix for 10 PCA dimensions:\n",
      "  [[1082   11]\n",
      " [  26   93]]\n",
      "Accuracy for 10 PCA dimensions:  0.97\n",
      "Recall for 10 PCA dimensions:  0.78\n",
      "Precision for 10 PCA dimensions:  0.89\n",
      "F1 for 10 PCA dimensions, 50 n_estimator  0.91\n",
      "---------\n",
      "Confusion matrix for 10 PCA dimensions:\n",
      "  [[1086    7]\n",
      " [  28   91]]\n",
      "Accuracy for 10 PCA dimensions:  0.97\n",
      "Recall for 10 PCA dimensions:  0.76\n",
      "Precision for 10 PCA dimensions:  0.93\n",
      "F1 for 10 PCA dimensions, 150 n_estimator  0.91\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "pca_df_inp = pca_df.iloc[:,:-2]\n",
    "n_estims = [5,10,50,100,150,200]\n",
    "best_acc = -float('inf')\n",
    "best_dim = -1\n",
    "best_recall = -1\n",
    "best_prec = -1\n",
    "best_f1 = -1\n",
    "\n",
    "# try different values of number of estimators and PCA dimension \n",
    "for pca_dim in np.linspace(2,200,100).astype(int):\n",
    "    for nests in n_estims:\n",
    "            X = pca_df_inp.iloc[:,:pca_dim]\n",
    "            \n",
    "            isolation_forest = IsolationForest(n_estimators=nests, \n",
    "                                               max_samples= 'auto',\n",
    "                                               random_state=42)\n",
    "\n",
    "            if_labels = isolation_forest.fit_predict(X)\n",
    "            if_labels = np.where(if_labels == -1, 1, 0)\n",
    "\n",
    "            conf_mat   = confusion_matrix(y_train,if_labels)\n",
    "            acc        = accuracy_score(y_train,if_labels)\n",
    "            recall     = recall_score(y_train,if_labels)\n",
    "            prec       = precision_score(y_train,if_labels)\n",
    "            f1         = f1_score(y_train,if_labels,average='macro')\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_acc = acc\n",
    "                best_dim = pca_dim\n",
    "                best_recall  = recall\n",
    "                best_prec = prec\n",
    "                best_if_labels = if_labels\n",
    "                best_f1 = f1\n",
    "                print(f'Confusion matrix for {pca_dim} PCA dimensions:\\n', \n",
    "                      f' {conf_mat}')\n",
    "                print(f'Accuracy for {pca_dim} PCA dimensions:', \n",
    "                      f' {acc:.2f}')\n",
    "                print(f'Recall for {pca_dim} PCA dimensions:', \n",
    "                      f' {recall:.2f}')\n",
    "                print(f'Precision for {pca_dim} PCA dimensions:', \n",
    "                      f' {prec:.2f}')\n",
    "                print(f'F1 for {pca_dim} PCA dimensions, {nests} n_estimator', \n",
    "                      f' {f1:.2f}')\n",
    "                print(f'---------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366175a6",
   "metadata": {},
   "source": [
    "## Best combined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21fcb258",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for ((0, 0, 0, 0, 0)) included and 0:\n",
      "  [[1093    0]\n",
      " [ 119    0]]\n",
      "Accuracy for ((0, 0, 0, 0, 0)) included and 0:  0.90\n",
      "Recall for ((0, 0, 0, 0, 0)) included and 0:  0.00\n",
      "Precision for ((0, 0, 0, 0, 0)) included and 0:  0.00\n",
      "F1 for ((0, 0, 0, 0, 0)) included and 0:  0.47\n",
      "---------\n",
      "Confusion matrix for ((0, 0, 0, 0, 1)) included and 0:\n",
      "  [[1075   18]\n",
      " [  15  104]]\n",
      "Accuracy for ((0, 0, 0, 0, 1)) included and 0:  0.97\n",
      "Recall for ((0, 0, 0, 0, 1)) included and 0:  0.87\n",
      "Precision for ((0, 0, 0, 0, 1)) included and 0:  0.85\n",
      "F1 for ((0, 0, 0, 0, 1)) included and 0:  0.92\n",
      "---------\n",
      "Confusion matrix for ((0, 0, 1, 0, 0)) included and 0:\n",
      "  [[1070   23]\n",
      " [   1  118]]\n",
      "Accuracy for ((0, 0, 1, 0, 0)) included and 0:  0.98\n",
      "Recall for ((0, 0, 1, 0, 0)) included and 0:  0.99\n",
      "Precision for ((0, 0, 1, 0, 0)) included and 0:  0.84\n",
      "F1 for ((0, 0, 1, 0, 0)) included and 0:  0.95\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "best_acc = -float('inf')\n",
    "best_dim = -1\n",
    "best_recall = -1\n",
    "best_prec = -1\n",
    "best_f1 = -1\n",
    "\n",
    "# aggregate labels predicted by a randomly selected subset of the models above\n",
    "for i1 in [0,1]:\n",
    "    for i2 in [0,1]:\n",
    "        for i3 in [0,1]:\n",
    "            for i4 in [0,1]:\n",
    "                for i5 in [0,1]:\n",
    "                    for thresh in [0,1]:\n",
    "                        tot = i1+i2+i3+i4+i5\n",
    "                        comb_labels = i1*best_if_labels + i2*best_oneclass_labels + i3*best_dbscan_labels + i4*kmeans_labels + i5*best_knn_labels\n",
    "                        # set label to 1 if the count of 1's in the collective output surpasses half the total number of models in the ensemble\n",
    "                        comb_labels = np.where(comb_labels > tot//2 + thresh, 1, 0)\n",
    "\n",
    "                        conf_mat   = confusion_matrix(y_train,comb_labels)\n",
    "                        acc        = accuracy_score(y_train,comb_labels)\n",
    "                        recall     = recall_score(y_train,comb_labels)\n",
    "                        prec       = precision_score(y_train,comb_labels)\n",
    "                        f1         = f1_score(y_train,comb_labels,average='macro')\n",
    "\n",
    "                        if f1 > best_f1:\n",
    "                            best_acc = acc\n",
    "                            best_dim = pca_dim\n",
    "                            best_recall  = recall\n",
    "                            best_prec = prec\n",
    "                            best_if_labels = if_labels\n",
    "                            best_f1 = f1\n",
    "                            print(f'Confusion matrix for ({i1,i2,i3,i4,i5}) included and {thresh}:\\n', \n",
    "                                  f' {conf_mat}')\n",
    "                            print(f'Accuracy for ({i1,i2,i3,i4,i5}) included and {thresh}:', \n",
    "                                  f' {acc:.2f}')\n",
    "                            print(f'Recall for ({i1,i2,i3,i4,i5}) included and {thresh}:', \n",
    "                                  f' {recall:.2f}')\n",
    "                            print(f'Precision for ({i1,i2,i3,i4,i5}) included and {thresh}:', \n",
    "                                  f' {prec:.2f}')\n",
    "                            print(f'F1 for ({i1,i2,i3,i4,i5}) included and {thresh}:', \n",
    "                                  f' {f1:.2f}')\n",
    "                            print(f'---------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dff948",
   "metadata": {},
   "source": [
    "# Testing on Test Data I Using Best Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffdac69",
   "metadata": {},
   "source": [
    "## Import Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0306e2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb components:  200\n",
      "Data directory:  ../datasets/test/data_heatmap_test.csv\n"
     ]
    }
   ],
   "source": [
    "# read the test data of data I from datasets folder\n",
    "!python3 pca_pipeline_combine_gridid.py 200 '../datasets/test/data_heatmap_test.csv'\n",
    "\n",
    "pca_test = pd.read_csv('temp/pca_df.csv')\n",
    "pca_test = pca_test.iloc[:,1:]\n",
    "y_test = pca_test[['label']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16141c38",
   "metadata": {},
   "source": [
    "## One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6590f851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for 172 PCA dimensions:\n",
      "  [[161 309]\n",
      " [  0  51]]\n",
      "F1 Score for 172 PCA dimensions:  0.38\n"
     ]
    }
   ],
   "source": [
    "# Best Model is with 172 PCA dimensions\n",
    "pca_dim = 172\n",
    "\n",
    "X_train = pca_df_inp.iloc[:,:pca_dim]\n",
    "X_test = pca_test.iloc[:,:pca_dim]\n",
    "\n",
    "oneclass = OneClassSVM(gamma = 'auto').fit(X_train)\n",
    "oneclass_labels = oneclass.predict(X_test)\n",
    "    \n",
    "oneclass_labels = np.where(oneclass_labels == 1, 0,1)\n",
    "conf_mat   = confusion_matrix(y_test,oneclass_labels)\n",
    "acc        = accuracy_score(y_test,oneclass_labels)\n",
    "recall     = recall_score(y_test,oneclass_labels)\n",
    "prec       = precision_score(y_test,oneclass_labels)\n",
    "f1         = f1_score(y_test,oneclass_labels,average='macro')\n",
    "\n",
    "print(f'Confusion matrix for {pca_dim} PCA dimensions:\\n', \n",
    "              f' {conf_mat}')\n",
    "#print(f'Accuracy for {pca_dim} PCA dimensions:', \n",
    "#              f' {acc:.2f}')\n",
    "#print(f'Recall for {pca_dim} PCA dimensions:', \n",
    "#              f' {recall:.2f}')\n",
    "#print(f'Precision for {pca_dim} PCA dimensions:', \n",
    "#              f' {prec:.2f}')\n",
    "print(f'F1 Score for {pca_dim} PCA dimensions:', \n",
    "              f' {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1588c99",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a34736ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on X_test:\n",
      "[[461   9]\n",
      " [  8  43]]\n",
      "Accuracy on X_test: 0.97\n",
      "F1 Score on X_test: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Perform PCA on X_train and X_test with 10 dimensions\n",
    "PCA = 10\n",
    "nn = 10\n",
    "thres = 90\n",
    "\n",
    "X_train = pca_df_inp.iloc[:, :PCA]  \n",
    "X_test = pca_test.iloc[:, :PCA] \n",
    "\n",
    "# Train k-NN model on X_train_pca with 10 neighbors\n",
    "knn = NearestNeighbors(n_neighbors=nn, algorithm='auto', metric='euclidean')\n",
    "knn.fit(X_train)\n",
    "\n",
    "# Predict anomalies on X_test_pca\n",
    "distances, indices = knn.kneighbors(X_test)\n",
    "anomaly_scores = distances.mean(axis=1)\n",
    "threshold = np.percentile(anomaly_scores, thres)\n",
    "\n",
    "# Convert labels to binary (0: inliers, 1: outliers)\n",
    "knn_labels = np.where(anomaly_scores > threshold, 1, 0)\n",
    "\n",
    "# Evaluate the performance on X_test\n",
    "conf_mat = confusion_matrix(y_test, knn_labels)\n",
    "acc = accuracy_score(y_test, knn_labels)\n",
    "f1 = f1_score(y_test, knn_labels,average='macro')\n",
    "\n",
    "print(f'Confusion matrix on X_test:\\n{conf_mat}')\n",
    "print(f'Accuracy on X_test: {acc:.2f}')\n",
    "print(f'F1 Score on X_test: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b1af49",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5255e1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[245 225]\n",
      " [ 13  38]]\n",
      "Test accuracy: 0.54\n",
      "Test precision: 0.14\n",
      "Test recall: 0.75\n",
      "Test f1-score: 0.46\n"
     ]
    }
   ],
   "source": [
    "pca = 2\n",
    "k = 2\n",
    "\n",
    "X = pca_df_inp.iloc[:,:pca]\n",
    "kmeans = KMeans(n_clusters = k, random_state=42)\n",
    "kmeans.fit(X)\n",
    "kmeans_labels = kmeans.predict(pca_test.iloc[:,:pca])\n",
    "conf_mat = confusion_matrix(y_test,kmeans_labels)\n",
    "acc = accuracy_score(y_test,kmeans_labels)\n",
    "recall = recall_score(y_test,kmeans_labels)\n",
    "prec = precision_score(y_test,kmeans_labels)\n",
    "f1 = f1_score(y_test,kmeans_labels,average='macro')\n",
    "print(conf_mat)\n",
    "print(f'Test accuracy: {acc:.2f}')\n",
    "print(f'Test precision: {prec:.2f}')\n",
    "print(f'Test recall: {recall:.2f}')\n",
    "print(f'Test f1-score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb1d909",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88c39e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance on test data:\n",
      "Confusion matrix:\n",
      "[[430  40]\n",
      " [  0  51]]\n",
      "Accuracy: 0.92\n",
      "F1 Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "PCA = 8\n",
    "eps = 5\n",
    "min_sam = 10\n",
    "\n",
    "# Apply PCA with 8 dimensions\n",
    "X_train = pca_df_inp.iloc[:, :PCA]  \n",
    "X_test = pca_test.iloc[:, :PCA] \n",
    "\n",
    "# Fit DBSCAN model\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_sam)\n",
    "dbscan_labels_train = dbscan.fit_predict(X_train)\n",
    "dbscan_labels_test = dbscan.fit_predict(X_test)\n",
    "\n",
    "# Convert labels to binary (0: inliers, 1: outliers)\n",
    "dbscan_labels_train = np.where(dbscan_labels_train >= 0, 0, 1)\n",
    "dbscan_labels_test = np.where(dbscan_labels_test >= 0, 0, 1)\n",
    "\n",
    "# Evaluate performance on test data\n",
    "conf_mat_test = confusion_matrix(y_test, dbscan_labels_test)\n",
    "acc_test = accuracy_score(y_test, dbscan_labels_test)\n",
    "f1_test = f1_score(y_test, dbscan_labels_test,average='macro')\n",
    "\n",
    "print(\"\\nPerformance on test data:\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(conf_mat_test)\n",
    "print(f\"Accuracy: {acc_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb657f91",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcdf53d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for 10 PCA dimensions:\n",
      "  [[464   6]\n",
      " [  8  43]]\n",
      "F1 Score for 10 PCA dimensions with n_estimator = 150:  0.92\n"
     ]
    }
   ],
   "source": [
    "# Best Model for Isolation Forest is with 10 PCA and n_estimators = 150\n",
    "pca_dim = 10\n",
    "best_n_est = 150\n",
    "X_train = pca_df_inp.iloc[:,:pca_dim]\n",
    "X_test = pca_test.iloc[:,:pca_dim]\n",
    "            \n",
    "isolation_forest = IsolationForest(n_estimators=best_n_est, \n",
    "                                   max_samples='auto', \n",
    "                                   random_state=42)\n",
    "\n",
    "model = isolation_forest.fit(X_train)\n",
    "if_labels = model.predict(X_test)\n",
    "if_labels = np.where(if_labels == -1, 1, 0)\n",
    "\n",
    "conf_mat   = confusion_matrix(y_test,if_labels)\n",
    "acc        = accuracy_score(y_test,if_labels)\n",
    "recall     = recall_score(y_test,if_labels)\n",
    "prec       = precision_score(y_test,if_labels)\n",
    "f1         = f1_score(y_test, if_labels,average='macro')\n",
    "\n",
    "\n",
    "print(f'Confusion matrix for {pca_dim} PCA dimensions:\\n', \n",
    "                      f' {conf_mat}')\n",
    "print(f'F1 Score for {pca_dim} PCA dimensions with n_estimator = {best_n_est}:', \n",
    "                      f' {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c4b8ef",
   "metadata": {},
   "source": [
    "## Best Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee6f2005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for ((1, 1, 1, 1, 1)) included and 1:\n",
      "  [[465   5]\n",
      " [  6  45]]\n",
      "Best f1 score: 0.94\n"
     ]
    }
   ],
   "source": [
    "best_acc = -float('inf')\n",
    "best_dim = -1\n",
    "best_recall = -1\n",
    "best_prec = -1\n",
    "best_f1 = -1\n",
    "\n",
    "for i1 in [0,1]:\n",
    "    for i2 in [0,1]:\n",
    "        for i3 in [0,1]:\n",
    "            for i4 in [0,1]:\n",
    "                for i5 in [0,1]:\n",
    "                    for thresh in [0,1]:\n",
    "                        tot = i1+i2+i3+i4+i5\n",
    "                        comb_labels = i1*if_labels + i2*oneclass_labels + i3*dbscan_labels_test + \\\n",
    "                                        i4*kmeans_labels + i5*knn_labels\n",
    "                        comb_labels = np.where(comb_labels > tot//2 + thresh, 1, 0)\n",
    "\n",
    "                        conf_mat   = confusion_matrix(y_test,comb_labels)\n",
    "                        acc        = accuracy_score(y_test,comb_labels)\n",
    "                        recall     = recall_score(y_test,comb_labels)\n",
    "                        prec       = precision_score(y_test,comb_labels)\n",
    "                        f1         = f1_score(y_test,comb_labels,average='macro')\n",
    "\n",
    "                        if acc > best_acc:\n",
    "                            best_acc = acc\n",
    "                            best_recall  = recall\n",
    "                            best_prec = prec\n",
    "                            best_conf_mat = conf_mat\n",
    "                            best_f1 = f1\n",
    "print(f'Confusion matrix for ({i1,i2,i3,i4,i5}) included and {thresh}:\\n', f' {conf_mat}')\n",
    "print(f'Best f1 score: {best_f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f0bcee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
